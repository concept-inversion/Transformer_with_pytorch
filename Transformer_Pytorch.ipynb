{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch implementation of Transformer\n",
    "Code heavily inspired from https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec#d554."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from graphviz import Digraph\n",
    "import numpy as np\n",
    "import math\n",
    "import spacy\n",
    "#import en_core_web_sm\n",
    "#import fr_core_news_sm\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "from torchviz import make_dot\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenizer\n",
    "![alt text](sentence_token.png \"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "en = open('english.txt', encoding='utf-8').read().split('\\n')\n",
    "fr = open('french.txt', encoding='utf-8').read().split('\\n')\n",
    "\n",
    "en_ = spacy.load('en_core_web_sm')\n",
    "fr_ = spacy.load('fr_core_news_sm')\n",
    "\n",
    "def tokenize_en(sentence):\n",
    "    return [tok.text for tok in en_.tokenizer(sentence)]\n",
    "def tokenize_fr(sentence):\n",
    "    return [tok.text for tok in fr_.tokenizer(sentence)]\n",
    "EN_TEXT = Field(tokenize=tokenize_en)\n",
    "FR_TEXT = Field(tokenize=tokenize_fr, init_token = \"<sos>\", eos_token = \"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data into dataframe\n",
    "raw_data = {'English' : [line for line in en], 'French': [line for line in fr]}\n",
    "df = pd.DataFrame(raw_data, columns=[\"English\", \"French\"])\n",
    "# remove very long sentences and sentences where translations are \n",
    "# not of roughly equal length\n",
    "df['eng_len'] = df['English'].str.count(' ')\n",
    "df['fr_len'] = df['French'].str.count(' ')\n",
    "df = df.query('fr_len < 80 & eng_len < 80')\n",
    "df = df.query('fr_len < eng_len * 1.5 & fr_len * 1.5 > eng_len')\n",
    "df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train and validation set\n",
    "train, val = train_test_split(df,test_size=0.1)\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "val.to_csv(\"val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenized train and validation\n",
    "data_fields = [('English', EN_TEXT), ('French', FR_TEXT)]\n",
    "train,val = TabularDataset.splits(path='./', train='train.csv', validation='val.csv', format='csv', fields=data_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index tokens\n",
    "FR_TEXT.build_vocab(train, val)\n",
    "EN_TEXT.build_vocab(train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = BucketIterator(train, batch_size=1, \\\n",
    " shuffle=False,repeat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size:\n",
    "In each batch, the sentences have been transposed so they are descending vertically (important: we will need to transpose these again to work with the transformer). Each index represents a token (word), and each column represents a sentence. We have 10 columns, as 10 was the batch_size we specified.\n",
    "\n",
    "#### Determine batch size:\n",
    "Additionally, if your RAM can process say 1500 tokens each iteration, and your batch_size is 20, then only when you have batches of length 75 will you be utilising all the memory. An efficient batching mechanism would change the batch size depending on the sequence length to make sure around 1500 tokens were being processed each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2],\n",
      "        [10591],\n",
      "        [    3]])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch.French)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask Generation for input\n",
    "def input_mask_gen(EN_TEXT,input_seq):\n",
    "    #input_seq = batch.English.transpose(0,1)\n",
    "    input_pad = EN_TEXT.vocab.stoi['<pad>']\n",
    "    # creates mask with 0s wherever there is padding in the input\n",
    "    input_msk = (input_seq != input_pad).unsqueeze(1)\n",
    "    return input_msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask for target sequence\n",
    "def target_mask_gen(FR_TEXT,target_seq):\n",
    "    #target_seq = batch.French.transpose(0,1)\n",
    "    target_pad = FR_TEXT.vocab.stoi['<pad>']\n",
    "    target_msk = (target_seq != target_pad).unsqueeze(1)\n",
    "    size = target_seq.size(1) # get seq_len for matrix\n",
    "    nopeak_mask = np.triu(np.ones((1, size, size),dtype=int),k=1).astype('uint8')\n",
    "    nopeak_mask = Variable(torch.from_numpy(nopeak_mask) == 0)\n",
    "#     import ipdb;ipdb.set_trace()\n",
    "    target_msk = target_msk & nopeak_mask\n",
    "    return target_msk, target_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When each word is fed into the network, this code will perform a look-up and retrieve its embedding vector. These vectors will then be learnt as a parameters by the model, adjusted with each iteration of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define word embeddings\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.embed=nn.Embedding(vocab_size, d_model)\n",
    "    def forward(self,x):\n",
    "        #print(list(self.embed.parameters()))\n",
    "       \n",
    "        #return x\n",
    "        return self.embed(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position Encoding \n",
    "  \n",
    "\n",
    "![alt text](position_encoding.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate positional encoding matrix with sin and cos function\n",
    "class positional_encoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 80):\n",
    "        super().__init__()\n",
    "        self.model_dim = d_model\n",
    "        # create a matrix for positional encoding\n",
    "        pos_encod= torch.zeros(max_seq_len, self.model_dim)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0,self.model_dim,2):\n",
    "                pos_encod[pos,i] = math.sin(pos/(10000**((2*i)/self.model_dim)))\n",
    "                pos_encod[pos,i+1] = math.cos(pos/(10000**((2*(i+1))/self.model_dim)))\n",
    "        pos_encod= pos_encod.unsqueeze(0)\n",
    "        self.register_buffer('pos_encod',pos_encod)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        # make embeddings\n",
    "        X = X * math.sqrt(self.model_dim)\n",
    "        # add constant\n",
    "        seq_len = X.size(1)\n",
    "#         import ipdb;ipdb.set_trace()\n",
    "        X = X + Variable(self.pos_encod[:,:seq_len], requires_grad=False)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Generation\n",
    "![alt text](Input_transformer.png \"Input black\")\n",
    "\n",
    "### MultiHead Attention\n",
    "![alt text](multihead.png \"Input black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-headed attention\n",
    "\n",
    "grads = {}\n",
    "results = {}\n",
    "def save_grad(name):\n",
    "    def hook(grad):\n",
    "        grads[name] = grad\n",
    "    return hook\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, model_dimension, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.model_dimension= model_dimension\n",
    "        self.keys_dim= model_dimension// heads\n",
    "        self.head= heads\n",
    "        \n",
    "        #query vector\n",
    "        self.q_linear= nn.Linear(model_dimension, model_dimension)\n",
    "        #value vector\n",
    "        self.v_linear= nn.Linear(model_dimension, model_dimension)\n",
    "        #key vector\n",
    "        self.k_linear= nn.Linear(model_dimension, model_dimension)\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "        \n",
    "        self.output= nn.Linear(model_dimension, model_dimension)\n",
    "        \n",
    "    def forward(self, query, keys, value, mask=None, name=None):\n",
    "        bs = query.size(0)\n",
    "        keys= self.k_linear(keys).view(bs, -1, self.head, self.keys_dim)\n",
    "        results['keys_'+name] = keys\n",
    "        keys.register_hook(save_grad('keys_grad_'+name))\n",
    "        query= self.q_linear(query).view(bs, -1, self.head, self.keys_dim)\n",
    "        results['query_'+name] = query\n",
    "        query.register_hook(save_grad('query_grad_'+name))\n",
    "        value= self.v_linear(value).view(bs, -1, self.head, self.keys_dim)\n",
    "        results['value_'+name]= value\n",
    "        value.register_hook(save_grad('value_grad_'+name))\n",
    "#         print('keys_'+name)\n",
    "#         print(keys)\n",
    "#         print('value_'+name)\n",
    "#         print(value)\n",
    "        keys= keys.transpose(1,2)\n",
    "        query= query.transpose(1,2)\n",
    "        value= value.transpose(1,2)\n",
    "        \n",
    "        attention_score= attention(query,keys,value,self.keys_dim,mask,self.dropout, name)        \n",
    "        results['attn_score_'+name] = attention_score\n",
    "        attention_score.register_hook(save_grad('attn_score_'+name))\n",
    "        # combine the result from all head\n",
    "        concat_result= attention_score.transpose(1,2).contiguous().view(bs, -1, self.model_dimension)\n",
    "        results['attn_concat_'+name] = concat_result\n",
    "        concat_result.register_hook(save_grad('attn_conct_'+name))        \n",
    "        # pass through a last layer to match the dimension (Multiply with Wo)\n",
    "        output= self.output(concat_result)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For encoder, \n",
    "#Dimension: Batch_size * seq_len * model_dimension\n",
    "# For Multi-head attention: (split into N heads)\n",
    "# Dimension: batch_size * N * seq_len * (model_dimension/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single attention\n",
    "![alt text](single_attention.png \"attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention: used by both encoder and decoder\n",
    "def attention(q, k, v, d_k, mask=None, dropout=None, name=None):\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "    results['score_'+name]=scores\n",
    "    scores.register_hook(save_grad('score_'+name))\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    results['scores_softmax_'+name]= scores\n",
    "    scores.register_hook(save_grad('score_softmax_'+name))\n",
    "    \n",
    "    if dropout is not None:\n",
    "        pass\n",
    "        #scores = dropout(scores)\n",
    "    \n",
    "    output = torch.matmul(scores, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define FeedForward \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,model_dimension, dim_forward=3, dropout= 0.1):\n",
    "        super().__init__()\n",
    "        self.linear_1= nn.Linear(model_dimension, dim_forward)\n",
    "        self.dropout= nn.Dropout(dropout)\n",
    "        self.linear_2= nn.Linear(dim_forward, model_dimension)\n",
    "    \n",
    "    def forward(self,X,name=\"None\"):\n",
    "        #print(\"Forward Layer\")\n",
    "        X= (F.relu(self.linear_1(X)))\n",
    "        results['x_linear_1_'+name] = X\n",
    "        #print(X)\n",
    "        #X.register_hook(save_grad('x_linear_1_'+name))\n",
    "        \n",
    "        X= self.linear_2(X)\n",
    "        results['x_linear_2_'+name] = X\n",
    "        #X.register_hook(save_grad('x_linear_2_'+name))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=results['x_linear_1_enc'].detach().numpy()\n",
    "#b=grads['x_linear_1_enc'].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.size = d_model\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "    def forward(self, x, name=None):\n",
    "#         print(\"++++++++++++++mean+++++++++++++++\")\n",
    "#         print(x.mean(dim=-1, keepdim=True))\n",
    "#         print(x.std(dim=-1, keepdim=True))\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        norm.register_hook(save_grad('norm_'+name))\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "![alt text](encoder.png \"attention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "   \n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
    "       # print(\"Att crossed\")\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        #print(\"Encoder out\")\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.ff= FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout) \n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.norm_1 = Norm(d_model) \n",
    "        self.norm_2 = Norm(d_model)\n",
    "        \n",
    "    def forward(self, x, mask):   \n",
    "        results['x'] = x\n",
    "        x2=x\n",
    "        #x2=self.norm_1(x,\"enc\")\n",
    "        results['x2']=x2\n",
    "        #x2.register_hook(save_grad('input_norm_out'))\n",
    "        results['input_norm'] = x2\n",
    "        \n",
    "        #x = x + self.dropout_1(self.attn(x2,x2,x2,mask,\"enc\"))\n",
    "        x = x + (self.attn(x2,x2,x2,mask,\"enc\"))\n",
    "        #x.register_hook(save_grad('enc_att_out'))\n",
    "        results['enc_attn_out'] = x\n",
    "        \n",
    "        xz=x\n",
    "        #xz= self.norm_2(x,\"enc\")\n",
    "        results['After_attn_norm'] = xz\n",
    "        #xz.register_hook(save_grad('after_norm'))\n",
    "        \n",
    "        x2 = x+ (self.ff(xz,'enc'))\n",
    "        results['enc_after_ff'] = x2\n",
    "        #x2.register_hook(save_grad('enc_after_ff'))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, model_dimension, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.normalize1= Norm(model_dimension)\n",
    "        self.normalize2= Norm(model_dimension)\n",
    "        self.normalize3= Norm(model_dimension)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attn_1 = MultiHeadAttention(heads, model_dimension)\n",
    "        self.attn_2 = MultiHeadAttention(heads, model_dimension)\n",
    "        self.ff = FeedForward(model_dimension)\n",
    "        \n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x2 = self.normalize1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "       # print(\"Dec passed 1\")\n",
    "        x2 = self.normalize2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs,src_mask))\n",
    "       # print(\"Dec passed 2\")\n",
    "        x2 = self.normalize3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, model_dimension, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn_1 = MultiHeadAttention(heads, model_dimension)\n",
    "        self.attn_2 = MultiHeadAttention(heads, model_dimension)\n",
    "        self.ff = FeedForward(model_dimension)\n",
    "        \n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x2=x\n",
    "        x = x + (self.attn_1(x2, x2, x2, trg_mask,\"dec\"))\n",
    "        x = x + (self.attn_2(x2, e_outputs, e_outputs,src_mask,\"dec\"))\n",
    "        x = x + (self.ff(x2,\"dec\"))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, model_dimension, N, heads):\n",
    "        super().__init__()\n",
    "        self.N= N\n",
    "        self.embed= Embedder(vocab_size, model_dimension)\n",
    "        self.position_encoder= positional_encoding(model_dimension)\n",
    "        self.layers= get_clones(EncoderLayer(model_dimension, heads), N)\n",
    "        self.normalized= Norm(model_dimension)\n",
    "        self.norm= Norm(model_dimension)\n",
    "    def forward(self, source, mask):\n",
    "        x= self.embed(source)\n",
    "        x= self.position_encoder(x)\n",
    "#         print(\"Encoder\")\n",
    "#         print(x)\n",
    "        results['input_encoding'] = x\n",
    "        #x.register_hook(save_grad('input_encod_encoder'))\n",
    "        for i in range(N):\n",
    "            #print(\"Encoder:\",i)\n",
    "            x= self.layers[i](x, mask)\n",
    "            results['enc_Ni_out'] = x\n",
    "            #x.register_hook(save_grad('enc_Ni_out'))\n",
    "        x_out= self.norm(x,\"enc\")\n",
    "        results['enc_out'] = x_out\n",
    "        x_out.register_hook(save_grad('enc_out'))\n",
    "        return x_out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, model_dimension, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, model_dimension)\n",
    "        self.positional_encoder = positional_encoding(model_dimension)\n",
    "        self.layers = get_clones(DecoderLayer(model_dimension, heads), N)\n",
    "        self.normalized= Norm(model_dimension)\n",
    "    \n",
    "    def forward(self, target,\n",
    "                e_output, source_mask, target_mask):\n",
    "        #print(target)\n",
    "        x= self.embed(target)\n",
    "        x= self.positional_encoder(x)\n",
    "#         print(\"Decoder\")\n",
    "#         print(x)\n",
    "        for i in range(self.N):\n",
    "            #print(\"Decoder:\",i)\n",
    "            x= self.layers[i](x, e_output, source_mask, target_mask)\n",
    "        return x\n",
    "        #return self.normalized(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.encoder= Encoder(src_vocab, d_model,N,heads)\n",
    "        self.decoder= Decoder(trg_vocab, d_model,N,heads)\n",
    "        self.output= nn.Linear(d_model, trg_vocab)\n",
    "    def forward(self, source, target, source_mask, target_mask):\n",
    "        encoder_out= self.encoder(source, source_mask)\n",
    "        decoder_out= self.decoder(target, encoder_out, source_mask, target_mask)\n",
    "        output= self.output(decoder_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dimension= 1024\n",
    "attention_heads= 1\n",
    "N = 1\n",
    "source_vocab= len(EN_TEXT.vocab)\n",
    "target_vocab= len(FR_TEXT.vocab)\n",
    "\n",
    "model= Transformer(source_vocab, target_vocab, model_dimension, N, attention_heads)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# initialize the parameters\n",
    "for p in model.parameters():\n",
    "    if p.dim()>1:\n",
    "        nn.init.xavier_normal_(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9,0.98), eps= 1e-9)\n",
    "def train_model(epochs, print_every=1):\n",
    "    model.train()\n",
    "    start_all = time.time()\n",
    "    start = time.time()\n",
    "    temp = start\n",
    "    total_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        #print(epoch)\n",
    "        c = 30;\n",
    "        for i,batch in enumerate(train_iter):\n",
    "            # print(\"Batch:\",i)\n",
    "            c= c-1\n",
    "            if(c<1):\n",
    "                break;\n",
    "            start = time.time()\n",
    "            src= batch.English.transpose(0,1)\n",
    "#             print(\"src\")\n",
    "#             print(src)\n",
    "            target= batch.French.transpose(0,1)\n",
    "            # Last word to predict\n",
    "            #import ipdb;ipdb.set_trace()\n",
    "            target_input= target[:,:-1]\n",
    "            targets = target[:, 1:].contiguous().view(-1)\n",
    "            source_mask= input_mask_gen(EN_TEXT,src)\n",
    "            target_mask,target_pad= target_mask_gen(FR_TEXT,target_input)\n",
    "            #z=make_dot(model(src, target_input, source_mask, target_mask),params=dict(model.named_parameters()))           \n",
    "            #z.view()\n",
    "            st= time.time()\n",
    "            preds= model(src, target_input, source_mask, target_mask)\n",
    "            #import ipdb;ipdb.set_trace()\n",
    "#             print(\"forward time:\",time.time()-st)\n",
    "            #print(\"done\")\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss= F.cross_entropy(preds.view(-1, preds.size(-1)),targets, ignore_index=target_pad)\n",
    "            star= time.time()\n",
    "            loss.backward()\n",
    "            #import ipdb;ipdb.set_trace()\n",
    "#             print(\"gradient computation time:\",time.time()-star)\n",
    "            start = time.time()\n",
    "            optimizer.step()\n",
    "#             print(\"update time:\",time.time()-start)\n",
    "            total_loss += loss.data\n",
    "            if (i + 1) % print_every == 0:\n",
    "                loss_avg = total_loss / print_every\n",
    "                print(\"time = %dm, epoch %d, iter = %d, loss = %.3f,\\\n",
    "                %ds per %d iters\" % ((time.time() - start) // 60,\n",
    "                epoch + 1, i + 1, loss_avg, time.time() - temp,\n",
    "                print_every))\n",
    "                total_loss = 0\n",
    "                temp = time.time()\n",
    "    print(\"OVerall time: \",time.time()-start_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 0m, epoch 1, iter = 1, loss = 9.977,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 2, loss = 14.619,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 3, loss = 9.995,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 4, loss = 9.663,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 5, loss = 8.060,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 6, loss = 13.183,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 7, loss = 9.336,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 8, loss = 10.978,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 9, loss = 9.173,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 10, loss = 8.333,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 11, loss = 9.617,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 12, loss = 9.482,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 13, loss = 9.431,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 14, loss = 8.950,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 15, loss = 8.765,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 16, loss = 8.632,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 17, loss = 8.624,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 18, loss = 8.540,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 19, loss = 8.002,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 20, loss = 9.771,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 21, loss = 7.309,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 22, loss = 8.492,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 23, loss = 8.610,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 24, loss = 8.148,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 25, loss = 8.668,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 26, loss = 8.852,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 27, loss = 6.330,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 28, loss = 7.272,                0s per 1 iters\n",
      "time = 0m, epoch 1, iter = 29, loss = 7.160,                0s per 1 iters\n",
      "OVerall time:  11.054260730743408\n"
     ]
    }
   ],
   "source": [
    "train_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.1950692 ,   8.160911  ,  -8.741374  , ..., -27.39594   ,\n",
       "          -6.054618  ,  21.88696   ],\n",
       "        [  1.8207047 ,   8.017043  ,  -8.295161  , ..., -26.978642  ,\n",
       "          -5.9500494 ,  21.364285  ],\n",
       "        [  1.369138  ,   6.832446  ,  -8.596656  , ..., -26.890856  ,\n",
       "          -6.5006127 ,  21.517189  ],\n",
       "        ...,\n",
       "        [ -0.84437275,   8.144324  , -10.158885  , ..., -27.03297   ,\n",
       "          -6.3935385 ,  21.171732  ],\n",
       "        [ -0.77687097,   8.395802  ,  -9.45327   , ..., -26.43468   ,\n",
       "          -6.0821395 ,  21.697058  ],\n",
       "        [  1.7248828 ,   8.588492  ,  -9.145571  , ..., -26.767185  ,\n",
       "          -6.7698135 ,  21.449507  ]]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['enc_after_ff'].detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5054742 , 0.5440578 , 0.5356682 , 0.5103475 , 0.4826672 ,\n",
       "        0.48721611, 0.48022857, 0.4599744 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= results['x'].detach().numpy()\n",
    "np.mean(x,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62725735, 0.60801345, 0.60049975, 0.6500525 , 0.62876284,\n",
       "        0.63606274, 0.62796223, 0.6690816 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(x,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 8192 into shape (9,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0a70efa7c5e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mbatchnorm_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 8192 into shape (9,2)"
     ]
    }
   ],
   "source": [
    "gamma = model.encoder.layers[0].norm_1.alpha.detach().numpy()\n",
    "beta = model.encoder.layers[0].norm_1.bias.detach().numpy()\n",
    "eps = model.encoder.layers[0].norm_1.eps\n",
    "x= results['x'].detach().numpy().reshape(9,2)\n",
    "batchnorm_forward(x,gamma,beta,eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.array([[0.7004],\n",
    "         [0.1070],\n",
    "         [0.0727],\n",
    "         [0.6342],\n",
    "         [1.2626],\n",
    "         [1.3580],\n",
    "         [0.9090],\n",
    "         [0.2514],\n",
    "         [0.0237]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std.shape\n",
    "#self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    " #       / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up=x-np.mean(x,axis=-1).reshape(9,1)\n",
    "down = std +eps\n",
    "(gamma * up/down) + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up/down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[[ 0.5199],\n",
    "         [ 0.9371],\n",
    "         [ 0.9490],\n",
    "         [ 0.5778],\n",
    "         [ 0.1163],\n",
    "         [ 0.0345],\n",
    "         [ 0.3737],\n",
    "         [ 0.8237],\n",
    "         [ 1.0051],\n",
    "         [ 0.7182],\n",
    "         [ 0.2459],\n",
    "         [-0.0167],\n",
    "         [ 0.2338]]], grad_fn=<MeanBackward1>)\n",
    "tensor([[[0.7014],\n",
    "         [0.1058],\n",
    "         [0.0953],\n",
    "         [0.5960],\n",
    "         [1.2205],\n",
    "         [1.3941],\n",
    "         [0.8999],\n",
    "         [0.2581],\n",
    "         [0.0250],\n",
    "         [0.4160],\n",
    "         [1.0935],\n",
    "         [1.4302],\n",
    "         [1.1078]]], grad_fn=<StdBackward1>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_forward(x, gamma, beta, eps):\n",
    "    \n",
    "    #import ipdb;ipdb.set_trace()\n",
    "    N, D = x.shape\n",
    "    #step1: calculate mean\n",
    "    mu = 1./N * np.sum(x, axis = -1).reshape(9,1)\n",
    "    #step2: subtract mean vector of every trainings example\n",
    "    xmu = x - mu\n",
    "      #step3: following the lower branch - calculation denominator\n",
    "    sq = xmu ** 2\n",
    "      #step4: calculate variance\n",
    "    var = 1./N * np.sum(sq, axis = -1).reshape(9,1)\n",
    "      #step5: add eps for numerical stability, then sqrt\n",
    "    sqrtvar = np.sqrt(var + eps)\n",
    "      #step6: invert sqrtwar\n",
    "    ivar = 1./sqrtvar\n",
    "      #step7: execute normalization\n",
    "    xhat = xmu * ivar\n",
    "      #step8: Nor the two transformation steps\n",
    "    gammax = gamma * xhat\n",
    "      #step9\n",
    "    out = gammax + beta\n",
    "      #store intermediate\n",
    "    cache = (xhat,gamma,xmu,ivar,sqrtvar,var,eps)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from scipy.special import softmax\n",
    "\n",
    "\n",
    "# In reality, for ML models, each column should represent one sequence. Hence, we need to transpose two times\n",
    "e_dim= 2;\n",
    "seq_len= 4;\n",
    "\n",
    "def normalize():\n",
    "    pass\n",
    "def normback():\n",
    "    pass\n",
    "\n",
    "def softmax1(x):\n",
    "    #return softmax(Z,axis=1)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def dropout(p,dim):\n",
    "    u1 = np.random.binomial(1, p, size=dim.shape)\n",
    "    return (p*u1)\n",
    "\n",
    "def Relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "# Input\n",
    "X= results['input_encoding'].detach().numpy()\n",
    "#import ipdb; ipdb.set_trace()\n",
    "# Normalize\n",
    "X_norm= results['input_norm'].detach().numpy()\n",
    "\n",
    "X_norm= X_norm[0]\n",
    "# Define Wq,bq; Wk, bk; Wv, bv\n",
    "Wq= model.encoder.layers[0].attn.q_linear.weight.detach().numpy()\n",
    "bq= model.encoder.layers[0].attn.q_linear.bias.detach().numpy()\n",
    "\n",
    "Wk= model.encoder.layers[0].attn.k_linear.weight.detach().numpy()\n",
    "bk= model.encoder.layers[0].attn.k_linear.bias.detach().numpy()\n",
    "\n",
    "Wv= model.encoder.layers[0].attn.v_linear.weight.detach().numpy()\n",
    "bv= model.encoder.layers[0].attn.v_linear.bias.detach().numpy()\n",
    "\n",
    "Q = np.dot(Wq,X_norm.transpose()).transpose() + bq\n",
    "#print(Q)\n",
    "K = np.dot(Wk,X_norm.transpose()).transpose() + bk\n",
    "#print(K)\n",
    "V = np.dot(Wv,X_norm.transpose()).transpose() + bv\n",
    "Z= np.dot(Q,np.transpose(K))/np.sqrt(e_dim)\n",
    "\n",
    "Z_res= softmax1(Z)\n",
    "\n",
    "Z_out = np.dot(Z_res,V)\n",
    "\n",
    "ZZ= (Z_out)\n",
    "# Define output parameter for attention\n",
    "Wo= model.encoder.layers[0].attn.output.weight.detach().numpy()\n",
    "bo= model.encoder.layers[0].attn.output.bias.detach().numpy()\n",
    "attn_out= np.dot(Wo, ZZ.transpose()).transpose() + bo \n",
    "\n",
    "Zo= attn_out + X\n",
    "\n",
    "Zoo= (Zo)\n",
    "\n",
    "# Normalized input before FC layer\n",
    "Zoo_norm= results['After_attn_norm'].detach().numpy()\n",
    "\n",
    "\n",
    "# Define weights for linear model\n",
    "w1= model.encoder.layers[0].ff.linear_1.weight.detach().numpy().transpose()\n",
    "b1= model.encoder.layers[0].ff.linear_1.bias.detach().numpy()\n",
    "\n",
    "w2= model.encoder.layers[0].ff.linear_2.weight.detach().numpy().transpose()\n",
    "b2= model.encoder.layers[0].ff.linear_2.bias.detach().numpy()\n",
    "\n",
    "Z_ff_1 = np.dot(Zoo_norm, w1) + b1\n",
    "\n",
    "Z_ff_1_relu = Relu(Z_ff_1)\n",
    "Z_ff_2 = np.dot(Z_ff_1_relu, w2) + b2\n",
    "\n",
    "H = Z_ff_2 + Zoo\n",
    "\n",
    "#E_out= normalize(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def batchnorm_backward(dout, cache):\n",
    "\n",
    "  #unfold the variables stored in cache\n",
    "  xhat,gamma,xmu,ivar,sqrtvar,var,eps = cache\n",
    "  #get the dimensions of the input/output\n",
    "  N,D = dout.shape\n",
    "  #step9\n",
    "  dbeta = np.sum(dout, axis=0)\n",
    "  dgammax = dout #not necessary, but more understandable\n",
    "  #step8\n",
    "  dgamma = np.sum(dgammax*xhat, axis=0)\n",
    "  dxhat = dgammax * gamma\n",
    "\n",
    "  #step7\n",
    "  divar = np.sum(dxhat*xmu, axis=0)\n",
    "  dxmu1 = dxhat * ivar\n",
    "  #step6\n",
    "  dsqrtvar = -1. /(sqrtvar**2) * divar\n",
    "  #step5\n",
    "  dvar = 0.5 * 1. /np.sqrt(var+eps) * dsqrtvar\n",
    "  #step4\n",
    "  dsq = 1. /N * np.ones((N,D)) * dvar\n",
    "  #step3\n",
    "  dxmu2 = 2 * xmu * dsq\n",
    "  #step2\n",
    "  dx1 = (dxmu1 + dxmu2)\n",
    "  dmu = -1 * np.sum(dxmu1+dxmu2, axis=0)\n",
    "  #step1\n",
    "  dx2 = 1. /N * np.ones((N,D)) * dmu\n",
    "  #step0\n",
    "  dx = dx1 + dx2\n",
    "  return dx, dgamma, dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# H gradients\n",
    "D_H = grads['enc_Ni_out'].numpy().reshape(X.shape[1],e_dim)\n",
    "\n",
    "# FC-2 Layer\n",
    "D_Z_ff_2 = D_H\n",
    "dw2= np.dot(D_Z_ff_2.transpose(), Z_ff_1_relu)\n",
    "db2= np.sum(D_Z_ff_2,axis=0)\n",
    "\n",
    "# Relu\n",
    "D_Z_ff_1_relu = Relu(np.dot(D_Z_ff_2 , w2.transpose()))\n",
    "\n",
    "#FC-1 Layer\n",
    "D_Z_ff_1 = D_Z_ff_1_relu\n",
    "dw1= np.dot(D_Z_ff_1.transpose(), Zoo)\n",
    "db1= np.sum(D_Z_ff_1, axis=0)\n",
    "\n",
    "# Normalize Gradients\n",
    "D_Zoo= np.dot(D_Z_ff_1, w1.transpose()) \n",
    "\n",
    "#gradients for Normalization \n",
    "D_Zo= (D_Zoo)\n",
    "\n",
    "# Attention output layer\n",
    "D_Z_attn_out= D_Zo\n",
    "dwo= np.dot(D_Z_attn_out.transpose(), ZZ)\n",
    "dbo= np.sum(D_Z_attn_out, axis=0)  \n",
    "\n",
    "# Gradient of combination\n",
    "D_ZZ= np.dot(D_Z_attn_out, Wo)\n",
    "\n",
    "# Score computation\n",
    "D_Z_out= D_ZZ\n",
    "D_Z= np.dot(D_Z_out.transpose(),V)\n",
    "D_V= np.dot(D_Z_out.transpose(),Z)   # *********\n",
    "\n",
    "# Softmax backprop\n",
    "D_Z_x= np.diag(Z) - np.dot(Z,Z.transpose()) #***********\n",
    "\n",
    "# Query and Key\n",
    "D_Q=  np.dot(D_Z_x, K)/np.sqrt(e_dim)\n",
    "D_K=  np.dot(D_Z_x.transpose(),Q)/np.sqrt(e_dim)\n",
    "\n",
    "# Gradient for V\n",
    "D_Wv= np.dot(D_V, X_norm)\n",
    "D_bv= np.sum(D_V,axis=0)\n",
    "D_norm_x_v= np.dot(D_V.transpose(), Wv)\n",
    "\n",
    "# Gradient for Q\n",
    "D_Wq= np.dot(D_Q.transpose(), X_norm)\n",
    "D_bq= np.sum(D_Q,axis=0)\n",
    "D_norm_x_q= np.dot(D_Q, Wq)\n",
    "\n",
    "# Gradient for K\n",
    "D_Wk= np.dot(D_K.transpose(), X_norm)\n",
    "D_bk= np.sum(D_K,axis=0)\n",
    "D_norm_x_k= np.dot(D_K, Wk)\n",
    "\n",
    "#**************If we want to update the embeddings **********************\n",
    "# SUm of all D_norm_X\n",
    "D_norm = D_norm_x_k + D_norm_x_q + D_norm_x_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(D_Z_ff_2,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D_Wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['x'].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=model.encoder.layers[0].norm_1.alpha.detach().numpy()\n",
    "bias=model.encoder.layers[0].norm_1.bias.detach().numpy()\n",
    "eps=model.encoder.layers[0].norm_1.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out,cache=batchnorm_forward(results['x'].detach().numpy().reshape(9,2),alpha,bias,eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=results['x2'].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.tensor([[ 0.0172,  1.0966],\n",
    "         [ 0.9420,  0.6059],\n",
    "         [ 1.0191, -0.4586],\n",
    "         [ 0.1643, -1.1157],\n",
    "         [-0.8335, -0.7352],\n",
    "         [-1.0699,  0.3336],\n",
    "         [-0.0000,  0.0000],\n",
    "         [ 0.7393,  0.8166],\n",
    "         [ 1.0900, -0.1723],\n",
    "         [ 0.4438, -1.0032],\n",
    "         [-0.5981, -0.9284],\n",
    "         [-1.1156,  0.0234],\n",
    "         [-0.6117,  0.0000],\n",
    "         [ 0.4853,  1.0180]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-1.0000,  1.0000],\n",
    "         [ 1.0000, -1.0000],\n",
    "         [ 1.0000, -1.0000],\n",
    "         [ 1.0000, -1.0000],\n",
    "         [-1.0000,  1.0000],\n",
    "         [-1.0000,  1.0000],\n",
    "         [ 0.0000,  0.0000],\n",
    "         [-1.0000,  1.0000],\n",
    "         [ 1.0000, -1.0000],\n",
    "         [ 1.0000, -1.0000],\n",
    "         [ 1.0000, -1.0000],\n",
    "         [-1.0000,  1.0000],\n",
    "         [-1.0000,  1.0000],\n",
    "         [-1.0000,  1.0000]]], grad_fn=<NativeLayerNormBackward>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [1,1]\n",
    "b= [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.layers[0].norm_1(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
